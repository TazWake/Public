#!/usr/bin/env python3
"""
Initial Malware Analysis Script

This script performs a comprehensive static analysis of executable files to identify
potential malicious characteristics. It supports multiple file formats (PE, ELF, Mach-O)
and checks for common indicators of compromise including:

- File structure and architecture identification
- Header analysis and metadata extraction
- Packing/obfuscation detection (entropy analysis)
- Suspicious string patterns
- Symbol and export analysis
- Size anomalies
- Common malware indicators

The script is designed to be extensible - new analysis modules can be easily added
by implementing new functions and integrating them into the main analysis pipeline.

Author: DFIR Tools Repository
License: See repository LICENSE file
"""

import os
import sys
import argparse
import math
import re
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from collections import Counter

# Optional imports with graceful fallback
try:
    import pefile
    HAS_PEFILE = True
except ImportError:
    HAS_PEFILE = False

try:
    import lief
    HAS_LIEF = True
except ImportError:
    HAS_LIEF = False

try:
    import yara
    HAS_YARA = True
except ImportError:
    HAS_YARA = False

try:
    from elftools.elf.elffile import ELFFile
    from elftools.elf.sections import SymbolTableSection
    HAS_ELFTOOLS = True
except ImportError:
    HAS_ELFTOOLS = False


# ============================================================================
# Utility Functions
# ============================================================================

def calculate_entropy(data: bytes) -> float:
    """
    Calculate Shannon entropy of a byte sequence.
    
    High entropy (>7.0) suggests encryption or packing.
    Normal executable code typically has entropy ~4.5-6.5.
    
    Args:
        data: Byte sequence to analyze
        
    Returns:
        Entropy value between 0.0 and 8.0
    """
    if not data:
        return 0.0
    
    byte_counts = Counter(data)
    length = len(data)
    entropy = 0.0
    
    for count in byte_counts.values():
        probability = count / length
        if probability > 0:
            entropy -= probability * math.log2(probability)
    
    return entropy


def extract_strings(data: bytes, min_length: int = 4) -> List[str]:
    """
    Extract printable ASCII strings from binary data.
    
    Args:
        data: Binary data to scan
        min_length: Minimum string length to extract
        
    Returns:
        List of extracted strings
    """
    strings: List[str] = []
    current_string = ""
    
    for byte in data:
        if 32 <= byte <= 126:  # Printable ASCII range
            current_string += chr(byte)
        else:
            if len(current_string) >= min_length:
                strings.append(current_string)
            current_string = ""
    
    if len(current_string) >= min_length:
        strings.append(current_string)
    
    return strings


def check_suspicious_strings(strings: List[str]) -> List[Tuple[str, str]]:
    """
    Identify suspicious strings that may indicate malicious activity.
    
    Args:
        strings: List of extracted strings
        
    Returns:
        List of tuples (string, reason) for suspicious matches
    """
    suspicious_patterns = {
        r'(?i)(password|passwd|pwd)': 'Password-related string',
        r'(?i)(cmd\.exe|powershell|wscript|cscript)': 'Command execution',
        r'(?i)(http://|https://|ftp://)': 'Network communication',
        r'(?i)(reg\s+add|reg\s+delete)': 'Registry manipulation',
        r'(?i)(createprocess|winexec|shellexecute)': 'Process creation API',
        r'(?i)(virtualalloc|virtualprotect)': 'Memory manipulation',
        r'(?i)(keylog|keystroke|hook)': 'Keylogging indicators',
        r'(?i)(backdoor|trojan|malware|virus)': 'Malware-related terms',
        r'(?i)(base64|base32|rot13)': 'Encoding/obfuscation',
        r'(?i)(xor|encrypt|decrypt|cipher)': 'Encryption/obfuscation',
        r'(?i)(\.onion|tor)': 'Tor/anonymity network',
        r'(?i)(exploit|payload|shellcode)': 'Exploitation terms',
    }
    
    suspicious: List[Tuple[str, str]] = []
    seen_strings = set()
    
    for string in strings:
        if string.lower() in seen_strings:
            continue
        seen_strings.add(string.lower())
        
        for pattern, reason in suspicious_patterns.items():
            if re.search(pattern, string):
                suspicious.append((string, reason))
                break
    
    return suspicious


# ============================================================================
# File Type Detection
# ============================================================================

def detect_file_type(filepath: str) -> Optional[str]:
    """
    Detect the executable file type by examining magic bytes.
    
    Args:
        filepath: Path to the file to analyze
        
    Returns:
        File type string ('PE', 'ELF', 'Mach-O', 'Unknown') or None if file not found
    """
    if not os.path.isfile(filepath):
        return None
    
    with open(filepath, 'rb') as f:
        magic = f.read(16)
    
    if len(magic) < 4:
        return 'Unknown'
    
    # PE (Portable Executable) - DOS header + PE signature
    if magic[:2] == b'MZ' and len(magic) >= 64:
        pe_offset = int.from_bytes(magic[60:64], 'little')
        if pe_offset < 1024 * 1024:  # Sanity check
            with open(filepath, 'rb') as f:
                f.seek(pe_offset)
                pe_sig = f.read(4)
                if pe_sig == b'PE\x00\x00':
                    return 'PE'
    
    # ELF (Executable and Linkable Format)
    if magic[:4] == b'\x7fELF':
        return 'ELF'
    
    # Mach-O (macOS/iOS)
    if magic[:4] in (b'\xfe\xed\xfa\xce', b'\xce\xfa\xed\xfe',  # 32-bit
                      b'\xfe\xed\xfa\xcf', b'\xcf\xfa\xed\xfe'):  # 64-bit
        return 'Mach-O'
    
    return 'Unknown'


# ============================================================================
# PE (Windows) Analysis
# ============================================================================

def analyze_pe_file(filepath: str) -> Dict[str, Any]:
    """
    Perform comprehensive analysis of a PE (Portable Executable) file.
    
    Args:
        filepath: Path to the PE file
        
    Returns:
        Dictionary containing analysis results
    """
    if not HAS_PEFILE:
        return {'error': 'pefile library not available. Install with: pip install pefile'}
    
    results: Dict[str, Any] = {
        'file_type': 'PE',
        'architecture': 'Unknown',
        'suspicious_indicators': [],
        'sections': [],
        'exports': [],
        'imports': [],
        'entropy': {},
        'metadata': {}
    }
    
    try:
        pe = pefile.PE(filepath)
        
        # Architecture
        machine_map = {
            0x014c: 'x86 (32-bit)',
            0x8664: 'x64 (64-bit)',
            0x01c0: 'ARM',
            0xaa64: 'ARM64',
        }
        machine = pe.FILE_HEADER.Machine
        results['architecture'] = machine_map.get(machine, f'Unknown (0x{machine:04x})')
        
        # File header metadata
        fh = pe.FILE_HEADER
        results['metadata'] = {
            'machine': f'0x{fh.Machine:04x}',
            'number_of_sections': fh.NumberOfSections,
            'timestamp': fh.TimeDateStamp,
            'characteristics': f'0x{fh.Characteristics:04x}',
        }
        
        # Optional header (if present)
        if hasattr(pe, 'OPTIONAL_HEADER'):
            oh = pe.OPTIONAL_HEADER
            results['metadata']['entry_point'] = f'0x{oh.AddressOfEntryPoint:08x}'
            results['metadata']['image_base'] = f'0x{oh.ImageBase:08x}'
            results['metadata']['size_of_image'] = oh.SizeOfImage
            results['metadata']['dll_characteristics'] = f'0x{oh.DllCharacteristics:04x}'
        
        # Section analysis
        section_entropies: List[float] = []
        suspicious_sections = []
        
        for section in pe.sections:
            section_name = section.Name.decode('utf-8', errors='ignore').rstrip('\x00')
            section_data = section.get_data()
            entropy = calculate_entropy(section_data)
            section_entropies.append(entropy)
            
            section_info = {
                'name': section_name,
                'virtual_address': f'0x{section.VirtualAddress:08x}',
                'virtual_size': section.Misc_VirtualSize,
                'raw_size': section.SizeOfRawData,
                'entropy': round(entropy, 2),
                'characteristics': f'0x{section.Characteristics:08x}'
            }
            results['sections'].append(section_info)
            
            # High entropy suggests packing/encryption
            if entropy > 7.0:
                suspicious_sections.append(f"{section_name} (entropy: {entropy:.2f})")
        
        # Overall file entropy
        with open(filepath, 'rb') as f:
            file_data = f.read()
        results['entropy']['overall'] = round(calculate_entropy(file_data), 2)
        if results['entropy']['overall'] > 7.5:
            results['suspicious_indicators'].append(
                f"High overall entropy ({results['entropy']['overall']}) - possible packing/encryption"
            )
        
        # Suspicious section names
        suspicious_names = ['UPX', '.packed', '.encrypted', '.obfus', '.themida', '.vmp']
        for section in results['sections']:
            if any(name in section['name'].upper() for name in suspicious_names):
                results['suspicious_indicators'].append(
                    f"Suspicious section name: {section['name']}"
                )
        
        # Exports
        if hasattr(pe, 'DIRECTORY_ENTRY_EXPORT'):
            for symbol in pe.DIRECTORY_ENTRY_EXPORT.symbols:
                name = symbol.name.decode('utf-8', errors='ignore') if symbol.name else '<no name>'
                results['exports'].append({
                    'name': name,
                    'ordinal': symbol.ordinal,
                    'address': f'0x{symbol.address:08x}'
                })
        
        # Imports
        if hasattr(pe, 'DIRECTORY_ENTRY_IMPORT'):
            for entry in pe.DIRECTORY_ENTRY_IMPORT:
                dll_name = entry.dll.decode('utf-8', errors='ignore')
                imports_list = []
                for imp in entry.imports:
                    func_name = imp.name.decode('utf-8', errors='ignore') if imp.name else f'Ordinal{imp.ordinal}'
                    imports_list.append(func_name)
                results['imports'].append({
                    'dll': dll_name,
                    'functions': imports_list
                })
                
                # Check for suspicious DLLs
                suspicious_dlls = ['kernel32.dll', 'ntdll.dll', 'advapi32.dll']
                if any(dll.lower() in dll_name.lower() for dll in suspicious_dlls):
                    # Check for suspicious functions
                    suspicious_funcs = ['VirtualAlloc', 'VirtualProtect', 'CreateRemoteThread',
                                      'WriteProcessMemory', 'SetWindowsHookEx', 'RegSetValue']
                    if any(func in str(imports_list) for func in suspicious_funcs):
                        results['suspicious_indicators'].append(
                            f"Suspicious API imports from {dll_name}"
                        )
        
        # Check for missing or unusual characteristics
        if fh.NumberOfSections < 3:
            results['suspicious_indicators'].append("Unusually low number of sections")
        
        if fh.NumberOfSections > 20:
            results['suspicious_indicators'].append("Unusually high number of sections")
        
        pe.close()
        
    except Exception as e:
        results['error'] = f"Error analyzing PE file: {str(e)}"
    
    return results


# ============================================================================
# ELF (Linux) Analysis
# ============================================================================

def analyze_elf_file(filepath: str) -> Dict[str, Any]:
    """
    Perform comprehensive analysis of an ELF (Executable and Linkable Format) file.
    
    Args:
        filepath: Path to the ELF file
        
    Returns:
        Dictionary containing analysis results
    """
    if not HAS_ELFTOOLS:
        return {'error': 'pyelftools library not available. Install with: pip install pyelftools'}
    
    results: Dict[str, Any] = {
        'file_type': 'ELF',
        'architecture': 'Unknown',
        'suspicious_indicators': [],
        'sections': [],
        'symbols': [],
        'entropy': {},
        'metadata': {}
    }
    
    try:
        with open(filepath, 'rb') as f:
            elf = ELFFile(f)
            
            # Architecture
            machine_map = {
                0x03: 'x86 (32-bit)',
                0x3E: 'x64 (64-bit)',
                0x28: 'ARM',
                0xB7: 'AArch64',
                0x08: 'MIPS',
            }
            machine = elf.header['e_machine']
            results['architecture'] = machine_map.get(machine, f'Unknown (0x{machine:02x})')
            
            # Header metadata
            results['metadata'] = {
                'type': elf.header['e_type'],
                'machine': f'0x{elf.header["e_machine"]:02x}',
                'entry_point': f'0x{elf.header["e_entry"]:016x}',
                'program_headers': elf.header['e_phnum'],
                'section_headers': elf.header['e_shnum'],
            }
            
            # Section analysis
            section_entropies: List[float] = []
            
            for section in elf.iter_sections():
                section_name = section.name
                section_data = section.data()
                entropy = calculate_entropy(section_data)
                section_entropies.append(entropy)
                
                section_info = {
                    'name': section_name,
                    'address': f'0x{section["sh_addr"]:016x}',
                    'size': section['sh_size'],
                    'entropy': round(entropy, 2),
                    'type': section['sh_type']
                }
                results['sections'].append(section_info)
                
                # High entropy detection
                if entropy > 7.0:
                    results['suspicious_indicators'].append(
                        f"High entropy in section {section_name} ({entropy:.2f}) - possible packing"
                    )
            
            # Symbol analysis
            for section in elf.iter_sections():
                if isinstance(section, SymbolTableSection):
                    for symbol in section.iter_symbols():
                        results['symbols'].append({
                            'name': symbol.name,
                            'value': f'0x{symbol.entry.st_value:016x}',
                            'size': symbol.entry.st_size,
                            'type': symbol.entry.st_info['type']
                        })
            
            # Overall entropy
            with open(filepath, 'rb') as f:
                file_data = f.read()
            results['entropy']['overall'] = round(calculate_entropy(file_data), 2)
            
            if results['entropy']['overall'] > 7.5:
                results['suspicious_indicators'].append(
                    f"High overall entropy ({results['entropy']['overall']}) - possible packing"
                )
            
    except Exception as e:
        results['error'] = f"Error analyzing ELF file: {str(e)}"
    
    return results


# ============================================================================
# Generic Analysis (for unsupported or unknown file types)
# ============================================================================

def analyze_generic_file(filepath: str) -> Dict[str, Any]:
    """
    Perform basic analysis on files of unknown or unsupported type.
    
    Args:
        filepath: Path to the file
        
    Returns:
        Dictionary containing basic analysis results
    """
    results: Dict[str, Any] = {
        'file_type': 'Unknown',
        'suspicious_indicators': [],
        'entropy': {},
        'size': 0
    }
    
    try:
        file_size = os.path.getsize(filepath)
        results['size'] = file_size
        
        with open(filepath, 'rb') as f:
            file_data = f.read()
        
        entropy = calculate_entropy(file_data)
        results['entropy']['overall'] = round(entropy, 2)
        
        if entropy > 7.5:
            results['suspicious_indicators'].append(
                f"High entropy ({entropy:.2f}) - possible encryption or packing"
            )
        
        # Extract and analyze strings
        strings = extract_strings(file_data)
        suspicious_strings = check_suspicious_strings(strings)
        
        if suspicious_strings:
            results['suspicious_strings'] = suspicious_strings
            results['suspicious_indicators'].append(
                f"Found {len(suspicious_strings)} suspicious strings"
            )
        
    except Exception as e:
        results['error'] = f"Error analyzing file: {str(e)}"
    
    return results


# ============================================================================
# Main Analysis Pipeline
# ============================================================================

def perform_analysis(filepath: str, yara_rules: Optional[str] = None) -> Dict[str, Any]:
    """
    Main analysis function that orchestrates the analysis pipeline.
    
    Args:
        filepath: Path to the file to analyze
        yara_rules: Optional path to YARA rules file for pattern matching
        
    Returns:
        Comprehensive analysis results dictionary
    """
    if not os.path.isfile(filepath):
        return {'error': f'File not found: {filepath}'}
    
    file_type = detect_file_type(filepath)
    
    # Route to appropriate analyzer
    if file_type == 'PE':
        results = analyze_pe_file(filepath)
    elif file_type == 'ELF':
        results = analyze_elf_file(filepath)
    else:
        results = analyze_generic_file(filepath)
        results['file_type'] = file_type or 'Unknown'
    
    # Common analysis for all file types
    file_size = os.path.getsize(filepath)
    results['file_size'] = file_size
    results['file_path'] = filepath
    
    # Size-based heuristics
    if file_size < 1024:  # Less than 1KB
        results['suspicious_indicators'].append("Unusually small file size")
    elif file_size > 50 * 1024 * 1024:  # Larger than 50MB
        results['suspicious_indicators'].append("Unusually large file size")
    
    # String analysis (if not already done)
    if 'suspicious_strings' not in results:
        try:
            with open(filepath, 'rb') as f:
                file_data = f.read()
            strings = extract_strings(file_data)
            suspicious_strings = check_suspicious_strings(strings)
            
            if suspicious_strings:
                results['suspicious_strings'] = suspicious_strings[:50]  # Limit output
                results['suspicious_indicators'].append(
                    f"Found {len(suspicious_strings)} suspicious strings"
                )
        except Exception:
            pass
    
    # YARA scanning (if available and rules provided)
    if HAS_YARA and yara_rules and os.path.isfile(yara_rules):
        try:
            rules = yara.compile(filepath=yara_rules)
            matches = rules.match(filepath=filepath)
            if matches:
                results['yara_matches'] = [str(match) for match in matches]
                results['suspicious_indicators'].append(
                    f"YARA rule matches: {len(matches)}"
                )
        except Exception as e:
            results['yara_error'] = f"YARA scan error: {str(e)}"
    
    return results


def print_results(results: Dict[str, Any]) -> None:
    """
    Print analysis results in a human-readable format.
    
    Args:
        results: Analysis results dictionary
    """
    print("=" * 80)
    print("MALWARE INITIAL ANALYSIS REPORT")
    print("=" * 80)
    print()
    
    if 'error' in results:
        print(f"[!] ERROR: {results['error']}")
        return
    
    print(f"File: {results.get('file_path', 'Unknown')}")
    print(f"Type: {results.get('file_type', 'Unknown')}")
    print(f"Architecture: {results.get('architecture', 'Unknown')}")
    print(f"Size: {results.get('file_size', 0):,} bytes")
    print()
    
    # Metadata
    if 'metadata' in results and results['metadata']:
        print("--- METADATA ---")
        for key, value in results['metadata'].items():
            print(f"  {key}: {value}")
        print()
    
    # Entropy
    if 'entropy' in results:
        print("--- ENTROPY ANALYSIS ---")
        if 'overall' in results['entropy']:
            entropy = results['entropy']['overall']
            print(f"  Overall entropy: {entropy:.2f}")
            if entropy > 7.5:
                print("  [!] HIGH ENTROPY - Possible packing or encryption")
            elif entropy > 6.5:
                print("  [*] Moderate entropy - May indicate obfuscation")
        print()
    
    # Sections
    if 'sections' in results and results['sections']:
        print("--- SECTIONS ---")
        for section in results['sections'][:10]:  # Limit output
            print(f"  {section.get('name', 'Unknown')}: "
                  f"entropy={section.get('entropy', 0):.2f}, "
                  f"size={section.get('size', section.get('raw_size', 0)):,}")
        if len(results['sections']) > 10:
            print(f"  ... and {len(results['sections']) - 10} more sections")
        print()
    
    # Exports/Symbols
    if 'exports' in results and results['exports']:
        print("--- EXPORTS ---")
        for exp in results['exports'][:20]:
            print(f"  {exp.get('name', 'Unknown')} (ordinal: {exp.get('ordinal', 0)})")
        if len(results['exports']) > 20:
            print(f"  ... and {len(results['exports']) - 20} more exports")
        print()
    
    if 'symbols' in results and results['symbols']:
        print("--- SYMBOLS ---")
        for sym in results['symbols'][:20]:
            print(f"  {sym.get('name', 'Unknown')}")
        if len(results['symbols']) > 20:
            print(f"  ... and {len(results['symbols']) - 20} more symbols")
        print()
    
    # Suspicious strings
    if 'suspicious_strings' in results:
        print("--- SUSPICIOUS STRINGS ---")
        for string, reason in results['suspicious_strings'][:20]:
            print(f"  [{reason}] {string[:80]}")
        if len(results['suspicious_strings']) > 20:
            print(f"  ... and {len(results['suspicious_strings']) - 20} more")
        print()
    
    # YARA matches
    if 'yara_matches' in results:
        print("--- YARA RULE MATCHES ---")
        for match in results['yara_matches']:
            print(f"  {match}")
        print()
    
    # Suspicious indicators summary
    if 'suspicious_indicators' in results and results['suspicious_indicators']:
        print("=" * 80)
        print("SUSPICIOUS INDICATORS SUMMARY")
        print("=" * 80)
        for i, indicator in enumerate(results['suspicious_indicators'], 1):
            print(f"  [{i}] {indicator}")
        print()
    else:
        print("--- NO OBVIOUS SUSPICIOUS INDICATORS DETECTED ---")
        print()


# ============================================================================
# Command Line Interface
# ============================================================================

def parse_args() -> argparse.Namespace:
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(
        description="Perform initial static analysis on executable files for malware indicators.",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  %(prog)s suspicious.exe
  %(prog)s malware.bin --yara-rules /path/to/rules.yar
  %(prog)s unknown_file --verbose

Dependencies:
  - pefile (for PE analysis): pip install pefile
  - pyelftools (for ELF analysis): pip install pyelftools
  - lief (alternative, supports multiple formats): pip install lief
  - yara-python (for YARA rule matching): pip install yara-python
        """
    )
    parser.add_argument(
        'filepath',
        help='Path to the executable file to analyze'
    )
    parser.add_argument(
        '--yara-rules',
        dest='yara_rules',
        metavar='PATH',
        help='Path to YARA rules file for pattern matching'
    )
    parser.add_argument(
        '-v', '--verbose',
        action='store_true',
        help='Enable verbose output (future use)'
    )
    return parser.parse_args()


def main() -> int:
    """Main entry point."""
    args = parse_args()
    
    # Check library availability
    print("[*] Checking analysis libraries...")
    if not HAS_PEFILE:
        print("  [!] pefile not available - PE file analysis will be limited")
    if not HAS_ELFTOOLS:
        print("  [!] pyelftools not available - ELF file analysis will be limited")
    if not HAS_YARA:
        print("  [!] yara-python not available - YARA rule matching disabled")
    print()
    
    # Perform analysis
    print(f"[*] Analyzing: {args.filepath}")
    print()
    
    results = perform_analysis(args.filepath, args.yara_rules)
    
    # Print results
    print_results(results)
    
    # Return exit code based on findings
    if 'suspicious_indicators' in results and results['suspicious_indicators']:
        return 1  # Suspicious indicators found
    return 0  # No obvious issues


if __name__ == '__main__':
    sys.exit(main())

