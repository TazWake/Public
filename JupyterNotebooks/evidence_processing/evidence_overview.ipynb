{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üß† Linux Evidence Overview & Triage Notebook\n",
        "\n",
        "This notebook is designed to help an investigator perform a quick, visual triage of a **mounted Linux evidence image** over a specified time window.\n",
        "\n",
        "It focuses on four questions:\n",
        "\n",
        "1. **Who logged in, from where, and when?** (user login events)\n",
        "2. **What commands were run?** (stack‚Äëranked from the audit log, if present)\n",
        "3. **What executable files appeared?** (new or modified executables in the window)\n",
        "4. **What SUID/SGID/sticky files exist?** (potential privilege‚Äëescalation footholds)\n",
        "\n",
        "## Environment prerequisites\n",
        "\n",
        "The notebook expects a Python environment with at least:\n",
        "\n",
        "- `pandas`, `matplotlib`, `seaborn`\n",
        "- A compatible `scipy` / `numpy` combination. If you see an error like *\"A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy\"*, run:\n",
        "  ```bash\n",
        "  pip install --upgrade scipy\n",
        "  ```\n",
        "  in the same environment as the notebook, then restart the kernel.\n",
        "\n",
        "## Workflow\n",
        "\n",
        "1. **Mount your evidence image read‚Äëonly** so that it looks like a normal Linux filesystem (for example at `/mnt/evidence`).\n",
        "2. In the next cell, set:\n",
        "   - `EVIDENCE_ROOT` to the mount point of the evidence image, and\n",
        "   - `DATE_FROM` / `DATE_TO` to the investigation time window.\n",
        "3. Run each section in order. Each will:\n",
        "   - Check for the relevant log / filesystem artifacts under `EVIDENCE_ROOT`.\n",
        "   - Limit analysis to the date range you specify.\n",
        "   - Produce **tables and charts** to help highlight anomalies.\n",
        "\n",
        "> **Note:** This notebook is **read‚Äëonly** with respect to the evidence. It walks the filesystem and parses log files, but does not modify them. Always work from a copy of the acquired evidence, not from original media.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üì¶ Imports & plotting setup\n",
        "import os\n",
        "import stat\n",
        "from datetime import datetime\n",
        "from typing import Optional, Tuple, List\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(style=\"darkgrid\")\n",
        "\n",
        "# Make plots a bit larger by default\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîß Evidence root and time window configuration\n",
        "\n",
        "# CHANGE ME: set this to the root of your mounted evidence image.\n",
        "# Example: EVIDENCE_ROOT = \"/mnt/evidence\"\n",
        "EVIDENCE_ROOT = \"/mnt/evidence\"  # or None to run against the live system (not recommended for real investigations)\n",
        "\n",
        "# CHANGE ME: investigation time window (inclusive)\n",
        "# Use ISO 8601 style strings; time is in local time of the evidence system unless you know otherwise.\n",
        "DATE_FROM = \"2024-01-01 00:00:00\"\n",
        "DATE_TO   = \"2024-01-31 23:59:59\"\n",
        "\n",
        "# Parsed datetime objects\n",
        "WINDOW_START = datetime.fromisoformat(DATE_FROM)\n",
        "WINDOW_END = datetime.fromisoformat(DATE_TO)\n",
        "\n",
        "print(f\"Evidence root     : {EVIDENCE_ROOT}\")\n",
        "print(f\"Analysis window   : {WINDOW_START} -> {WINDOW_END}\")\n",
        "\n",
        "if WINDOW_END <= WINDOW_START:\n",
        "    raise ValueError(\"DATE_TO must be after DATE_FROM\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üß± Helper functions\n",
        "\n",
        "def build_path(relative_path: str) -> str:\n",
        "    \"\"\"Build an absolute path into the evidence tree (or live system if EVIDENCE_ROOT is None).\"\"\"\n",
        "    if EVIDENCE_ROOT:\n",
        "        return os.path.join(EVIDENCE_ROOT, relative_path.lstrip(\"/\"))\n",
        "    return relative_path\n",
        "\n",
        "\n",
        "def in_window(ts: datetime) -> bool:\n",
        "    return WINDOW_START <= ts <= WINDOW_END\n",
        "\n",
        "\n",
        "def ensure_exists(path: str) -> bool:\n",
        "    exists = os.path.exists(path)\n",
        "    if not exists:\n",
        "        print(f\"[!] Missing expected file: {path}\")\n",
        "    return exists\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£ User login events (auth.log)\n",
        "\n",
        "This section parses `auth.log` (or equivalent) under the evidence root to identify **interactive login events** (typically via SSH).\n",
        "\n",
        "It extracts:\n",
        "\n",
        "- **Timestamp** (assuming the year from `DATE_FROM` if the log does not contain a year)\n",
        "- **Account name**\n",
        "- **Source IP address**\n",
        "\n",
        "Results are filtered to the configured time window, then visualised to highlight unusual **login times** or **source IPs**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import glob\n",
        "import gzip\n",
        "\n",
        "# Paths for auth-like log files; adjust here if your distro uses /var/log/secure\n",
        "AUTH_GLOB = build_path(\"/var/log/auth.log*\")\n",
        "auth_paths = sorted(glob.glob(AUTH_GLOB))\n",
        "\n",
        "print(\"Using auth log files:\")\n",
        "for p in auth_paths:\n",
        "    print(f\" - {p}\")\n",
        "\n",
        "if auth_paths:\n",
        "    login_records = []\n",
        "    year_hint = WINDOW_START.year\n",
        "\n",
        "    # Example auth.log line:\n",
        "    # Jan 10 12:34:56 hostname sshd[1234]: Accepted password for user from 1.2.3.4 port 5555 ssh2\n",
        "    login_re = re.compile(\n",
        "        r\"^(?P<month>\\w{3})\\s+(?P<day>\\d{1,2})\\s+(?P<time>\\d{2}:\\d{2}:\\d{2})\\s+\"  # syslog prefix\n",
        "        r\"(?P<host>\\S+)\\s+sshd\\[\\d+\\]:\\s+Accepted .* for (?P<user>\\S+) from (?P<ip>\\S+)\\s+\"\n",
        "    )\n",
        "\n",
        "    month_map = {m: i for i, m in enumerate(\n",
        "        [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"], start=1\n",
        "    )}\n",
        "\n",
        "    def open_maybe_gzip(path: str):\n",
        "        return gzip.open(path, \"rt\", errors=\"ignore\") if path.endswith(\".gz\") else open(path, \"r\", errors=\"ignore\")\n",
        "\n",
        "    for auth_path in auth_paths:\n",
        "        try:\n",
        "            f = open_maybe_gzip(auth_path)\n",
        "        except OSError:\n",
        "            continue\n",
        "        with f:\n",
        "            for line in f:\n",
        "                m = login_re.match(line)\n",
        "                if not m:\n",
        "                    continue\n",
        "                md = m.groupdict()\n",
        "                month = month_map.get(md[\"month\"])  # type: ignore\n",
        "                day = int(md[\"day\"])\n",
        "                t_str = md[\"time\"]\n",
        "\n",
        "                try:\n",
        "                    ts = datetime.strptime(f\"{year_hint}-{month:02d}-{day:02d} {t_str}\", \"%Y-%m-%d %H:%M:%S\")\n",
        "                except Exception:\n",
        "                    continue\n",
        "\n",
        "                if not in_window(ts):\n",
        "                    continue\n",
        "\n",
        "                login_records.append({\n",
        "                    \"timestamp\": ts,\n",
        "                    \"user\": md[\"user\"],\n",
        "                    \"ip\": md[\"ip\"],\n",
        "                })\n",
        "\n",
        "    if login_records:\n",
        "        login_df = pd.DataFrame(login_records).sort_values(\"timestamp\")\n",
        "        display(login_df.head())\n",
        "\n",
        "        # Timeline of logins\n",
        "        plt.figure(figsize=(12, 4))\n",
        "        sns.histplot(login_df[\"timestamp\"], bins=50)\n",
        "        plt.title(\"Login events over time\")\n",
        "        plt.xlabel(\"Time\")\n",
        "        plt.ylabel(\"Count\")\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Top source IPs\n",
        "        ip_counts = login_df[\"ip\"].value_counts().reset_index()\n",
        "        ip_counts.columns = [\"ip\", \"count\"]\n",
        "\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        sns.barplot(data=ip_counts.head(15), x=\"ip\", y=\"count\")\n",
        "        plt.title(\"Top source IPs for logins in window\")\n",
        "        plt.xticks(rotation=45, ha=\"right\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        print(\"No login events found in the specified window across any auth.log files.\")\n",
        "else:\n",
        "    print(\"No auth.log files found; skipping login event analysis.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2Ô∏è‚É£ Audit log command ranking (audit.log)\n",
        "\n",
        "If the Linux audit framework was enabled, `audit.log` can provide a **high‚Äëfidelity record of executed commands**.\n",
        "\n",
        "This section:\n",
        "\n",
        "- Parses `audit.log` under the evidence root.\n",
        "- Extracts timestamps and the primary executable/command.\n",
        "- Filters out obvious **background noise** (e.g. `cron`, `systemd`).\n",
        "- Stack‚Äëranks commands by frequency within the configured time window and visualises the top entries.\n",
        "\n",
        "> Parsing of audit logs varies across distributions; this implementation focuses on common `EXECVE` records and may not capture every variant.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parse and rank commands from audit.log (if present)\n",
        "\n",
        "AUDIT_GLOB = build_path(\"/var/log/audit/audit.log*\")\n",
        "audit_paths = sorted(glob.glob(AUDIT_GLOB))\n",
        "\n",
        "print(\"Using audit log files:\")\n",
        "for p in audit_paths:\n",
        "    print(f\" - {p}\")\n",
        "\n",
        "exec_records: List[dict] = []\n",
        "\n",
        "if audit_paths:\n",
        "    # Typical EXECVE line:\n",
        "    # type=EXECVE msg=audit(1697040000.123:123): argc=3 a0=\"bash\" a1=\"-c\" a2=\"whoami\"\n",
        "    ts_re = re.compile(r\"audit\\((?P<epoch>\\d+)(?:\\.\\d+)?:\")\n",
        "    cmd_re = re.compile(r\"\\ba0=\\\"(?P<cmd>[^\\\"]+)\\\"\")\n",
        "\n",
        "    for audit_path in audit_paths:\n",
        "        try:\n",
        "            f = gzip.open(audit_path, \"rt\", errors=\"ignore\") if audit_path.endswith(\".gz\") else open(audit_path, \"r\", errors=\"ignore\")\n",
        "        except OSError:\n",
        "            continue\n",
        "        with f:\n",
        "            for line in f:\n",
        "                if \" type=EXECVE \" not in line and not line.lstrip().startswith(\"type=EXECVE\"):\n",
        "                    continue\n",
        "\n",
        "                # Skip obvious background/system noise\n",
        "                if any(noise in line for noise in [\"cron\", \"CRON\", \"systemd\", \"anacron\"]):\n",
        "                    continue\n",
        "\n",
        "                ts_match = ts_re.search(line)\n",
        "                cmd_match = cmd_re.search(line)\n",
        "                if not ts_match or not cmd_match:\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    epoch = int(ts_match.group(\"epoch\"))\n",
        "                    ts = datetime.utcfromtimestamp(epoch)\n",
        "                except Exception:\n",
        "                    continue\n",
        "\n",
        "                if not in_window(ts):\n",
        "                    continue\n",
        "\n",
        "                exec_records.append({\n",
        "                    \"timestamp\": ts,\n",
        "                    \"command\": cmd_match.group(\"cmd\"),\n",
        "                })\n",
        "\n",
        "    if exec_records:\n",
        "        exec_df = pd.DataFrame(exec_records)\n",
        "        display(exec_df.head())\n",
        "\n",
        "        # Stack-rank commands\n",
        "        cmd_counts = exec_df[\"command\"].value_counts().reset_index()\n",
        "        cmd_counts.columns = [\"command\", \"count\"]\n",
        "\n",
        "        top5 = cmd_counts.head(5)\n",
        "        bottom5 = cmd_counts.tail(5) if len(cmd_counts) > 5 else cmd_counts\n",
        "\n",
        "        print(\"Top 5 commands by frequency:\")\n",
        "        display(top5)\n",
        "        print(\"Bottom 5 commands by frequency:\")\n",
        "        display(bottom5)\n",
        "\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        sns.barplot(data=top5, x=\"count\", y=\"command\")\n",
        "        plt.title(\"Top 5 commands from audit EXECVE events (within window)\")\n",
        "        plt.xlabel(\"Count\")\n",
        "        plt.ylabel(\"Command\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        if len(bottom5) > 0 and not bottom5.equals(top5):\n",
        "            plt.figure(figsize=(10, 4))\n",
        "            sns.barplot(data=bottom5.sort_values(\"count\"), x=\"count\", y=\"command\")\n",
        "            plt.title(\"Bottom 5 commands from audit EXECVE events (within window)\")\n",
        "            plt.xlabel(\"Count\")\n",
        "            plt.ylabel(\"Command\")\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "    else:\n",
        "        print(\"No EXECVE events in any audit.log file within the specified window (after filtering noise).\")\n",
        "else:\n",
        "    print(\"No audit.log files found; skipping audit command analysis.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3Ô∏è‚É£ Executable files created/changed in the window\n",
        "\n",
        "This section walks the evidence filesystem under `EVIDENCE_ROOT` and finds files that:\n",
        "\n",
        "- Are **regular files** with any execute bit set (user/group/other), and\n",
        "- Have either a modification time (`st_mtime`) **or** metadata/creation time (`st_ctime` / equivalent) within the investigation window.\n",
        "\n",
        "> The exact meaning of `st_ctime` is filesystem‚Äëdependent (on many Linux filesystems it records inode/metadata changes; on others it can expose true creation time). Here we simply treat it as an additional signal alongside `st_mtime`.\n",
        ">\n",
        "> The output highlights paths where new or changed executables appeared during the window, which may indicate **dropped tools, malware, or scripts**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Walk filesystem for executable files touched/created in the window\n",
        "\n",
        "if not EVIDENCE_ROOT:\n",
        "    print(\"[!] EVIDENCE_ROOT is not set; executable scan is intended for mounted evidence.\")\n",
        "else:\n",
        "    exec_records = []\n",
        "\n",
        "    for root, dirs, files in os.walk(EVIDENCE_ROOT):\n",
        "        for name in files:\n",
        "            path = os.path.join(root, name)\n",
        "            try:\n",
        "                st = os.stat(path, follow_symlinks=False)\n",
        "            except (FileNotFoundError, PermissionError, OSError):\n",
        "                continue\n",
        "\n",
        "            # Only regular files\n",
        "            if not stat.S_ISREG(st.st_mode):\n",
        "                continue\n",
        "\n",
        "            # Any execute bit set?\n",
        "            if not (st.st_mode & (stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH)):\n",
        "                continue\n",
        "\n",
        "            mtime = datetime.fromtimestamp(st.st_mtime)\n",
        "            ctime = datetime.fromtimestamp(st.st_ctime)\n",
        "            if not (in_window(mtime) or in_window(ctime)):\n",
        "                continue\n",
        "\n",
        "            rel_path = os.path.relpath(path, EVIDENCE_ROOT)\n",
        "            exec_records.append({\n",
        "                \"path\": rel_path,\n",
        "                \"mtime\": mtime,\n",
        "                \"ctime\": ctime,\n",
        "                \"mode\": oct(st.st_mode & 0o777),\n",
        "                \"size\": st.st_size,\n",
        "            })\n",
        "\n",
        "    if exec_records:\n",
        "        exec_fs_df = pd.DataFrame(exec_records).sort_values(\"mtime\")\n",
        "        display(exec_fs_df.head(20))\n",
        "\n",
        "        # Simple histogram by day (based on mtime)\n",
        "        exec_fs_df[\"date\"] = exec_fs_df[\"mtime\"].dt.date\n",
        "        counts_by_date = exec_fs_df[\"date\"].value_counts().sort_index()\n",
        "\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        counts_by_date.plot(kind=\"bar\")\n",
        "        plt.title(\"Executable files touched/created per day (within window)\")\n",
        "        plt.xlabel(\"Date\")\n",
        "        plt.ylabel(\"Count\")\n",
        "        plt.xticks(rotation=45, ha=\"right\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"No executable files found with mtime/ctime inside the specified window.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4Ô∏è‚É£ SUID/SGID/sticky bit files\n",
        "\n",
        "SUID, SGID, and sticky bits can be abused for **privilege escalation** or **persistence**.\n",
        "\n",
        "This section scans the mounted evidence tree for files and directories where any of these bits are set and summarises them.\n",
        "\n",
        "- **SUID (set‚Äëuser‚ÄëID)**: file runs with the file owner's UID\n",
        "- **SGID (set‚Äëgroup‚ÄëID)**: file runs with the file group's GID, or directory enforces group inheritance\n",
        "- **Sticky bit**: on directories, only file owners (or root) can delete/rename contained files\n",
        "\n",
        "The goal is to quickly surface unusual locations with these bits set for further manual review.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scan for SUID/SGID/sticky bit files and directories\n",
        "\n",
        "if not EVIDENCE_ROOT:\n",
        "    print(\"[!] EVIDENCE_ROOT is not set; SUID/SGID/sticky scan is intended for mounted evidence.\")\n",
        "else:\n",
        "    special_records = []\n",
        "\n",
        "    for root, dirs, files in os.walk(EVIDENCE_ROOT):\n",
        "        # Check directories (sticky/SGID often used on dirs)\n",
        "        for name in dirs:\n",
        "            path = os.path.join(root, name)\n",
        "            try:\n",
        "                st = os.stat(path, follow_symlinks=False)\n",
        "            except (FileNotFoundError, PermissionError, OSError):\n",
        "                continue\n",
        "\n",
        "            mode_bits = st.st_mode\n",
        "            special_mask = stat.S_ISUID | stat.S_ISGID | stat.S_ISVTX\n",
        "            if mode_bits & special_mask:\n",
        "                rel_path = os.path.relpath(path, EVIDENCE_ROOT)\n",
        "                special_records.append({\n",
        "                    \"type\": \"dir\",\n",
        "                    \"path\": rel_path,\n",
        "                    \"mode\": oct(mode_bits & 0o7777),\n",
        "                })\n",
        "\n",
        "        # Check files\n",
        "        for name in files:\n",
        "            path = os.path.join(root, name)\n",
        "            try:\n",
        "                st = os.stat(path, follow_symlinks=False)\n",
        "            except (FileNotFoundError, PermissionError, OSError):\n",
        "                continue\n",
        "\n",
        "            mode_bits = st.st_mode\n",
        "            special_mask = stat.S_ISUID | stat.S_ISGID | stat.S_ISVTX\n",
        "            if mode_bits & special_mask:\n",
        "                rel_path = os.path.relpath(path, EVIDENCE_ROOT)\n",
        "                special_records.append({\n",
        "                    \"type\": \"file\",\n",
        "                    \"path\": rel_path,\n",
        "                    \"mode\": oct(mode_bits & 0o7777),\n",
        "                })\n",
        "\n",
        "    if special_records:\n",
        "        special_df = pd.DataFrame(special_records).sort_values(\"path\")\n",
        "        display(special_df.head(50))\n",
        "\n",
        "        # Simple breakdown by type\n",
        "        by_type = special_df[\"type\"].value_counts()\n",
        "        print(\"\\nCounts by object type:\")\n",
        "        print(by_type)\n",
        "\n",
        "        # Breakdown by specific bit(s)\n",
        "        def classify_bits(mode_str: str) -> str:\n",
        "            mode_int = int(mode_str, 8)\n",
        "            flags = []\n",
        "            if mode_int & stat.S_ISUID:\n",
        "                flags.append(\"SUID\")\n",
        "            if mode_int & stat.S_ISGID:\n",
        "                flags.append(\"SGID\")\n",
        "            if mode_int & stat.S_ISVTX:\n",
        "                flags.append(\"STICKY\")\n",
        "            return \",\".join(flags) or \"none\"\n",
        "\n",
        "        special_df[\"bits\"] = special_df[\"mode\"].apply(classify_bits)\n",
        "        bits_counts = special_df[\"bits\"].value_counts()\n",
        "        print(\"\\nCounts by special bit combination:\")\n",
        "        print(bits_counts)\n",
        "    else:\n",
        "        print(\"No SUID/SGID/sticky bit objects found under the evidence root.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìÑ Generate triage report as Markdown\n",
        "\n",
        "from pathlib import Path\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "output_dir = Path(\".\")\n",
        "report_path = output_dir / \"evidence_triage_report.md\"\n",
        "\n",
        "sections: list[str] = []\n",
        "\n",
        "sections.append(\"# Linux Evidence Triage Report\")\n",
        "sections.append(\"\")\n",
        "sections.append(f\"- Evidence root: `{EVIDENCE_ROOT}`\")\n",
        "sections.append(f\"- Analysis window: {WINDOW_START} -> {WINDOW_END}\")\n",
        "sections.append(\"\")\n",
        "\n",
        "\n",
        "def add_df_section(title: str, df, max_rows: int = 20) -> None:\n",
        "    sections.append(f\"## {title}\")\n",
        "    if df is None or getattr(df, \"empty\", True):\n",
        "        sections.append(\"_No data available for this section in the selected window._\")\n",
        "    else:\n",
        "        sections.append(\"\")\n",
        "        sections.append(df.head(max_rows).to_markdown(index=False))\n",
        "    sections.append(\"\")\n",
        "\n",
        "\n",
        "# Login events\n",
        "login_df = globals().get(\"login_df\")\n",
        "add_df_section(\"Login events\", login_df)\n",
        "\n",
        "# Audit EXECVE command frequency (top/bottom 5)\n",
        "sections.append(\"## Audit EXECVE command frequency\")\n",
        "exec_top5 = globals().get(\"top5\")\n",
        "exec_bottom5 = globals().get(\"bottom5\")\n",
        "if exec_top5 is None or getattr(exec_top5, \"empty\", True):\n",
        "    sections.append(\"_No EXECVE command data available in this window (or audit.log missing)._\")\n",
        "else:\n",
        "    sections.append(\"### Top 5 commands by frequency\")\n",
        "    sections.append(exec_top5.to_markdown(index=False))\n",
        "    sections.append(\"\")\n",
        "    if exec_bottom5 is not None and not exec_bottom5.empty:\n",
        "        sections.append(\"### Bottom 5 commands by frequency\")\n",
        "        sections.append(exec_bottom5.to_markdown(index=False))\n",
        "sections.append(\"\")\n",
        "\n",
        "# Executable files touched/created\n",
        "exec_fs_df = globals().get(\"exec_fs_df\")\n",
        "add_df_section(\"Executable files touched/created in window\", exec_fs_df)\n",
        "\n",
        "# SUID/SGID/sticky entries\n",
        "special_df = globals().get(\"special_df\")\n",
        "add_df_section(\"SUID/SGID/sticky bit objects\", special_df)\n",
        "\n",
        "report_md = \"\\n\".join(sections)\n",
        "report_path.write_text(report_md, encoding=\"utf-8\")\n",
        "\n",
        "print(f\"Markdown report written to: {report_path.resolve()}\")\n",
        "display(Markdown(report_md))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìÑ Generate triage report as Markdown\n",
        "\n",
        "from pathlib import Path\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "output_dir = Path(\".\")\n",
        "report_path = output_dir / \"evidence_triage_report.md\"\n",
        "\n",
        "sections: list[str] = []\n",
        "\n",
        "sections.append(\"# Linux Evidence Triage Report\")\n",
        "sections.append(\"\")\n",
        "sections.append(f\"- Evidence root: `{EVIDENCE_ROOT}`\")\n",
        "sections.append(f\"- Analysis window: {WINDOW_START} -> {WINDOW_END}\")\n",
        "sections.append(\"\")\n",
        "\n",
        "\n",
        "def add_df_section(title: str, df, max_rows: int = 20) -> None:\n",
        "    sections.append(f\"## {title}\")\n",
        "    if df is None or getattr(df, \"empty\", True):\n",
        "        sections.append(\"_No data available for this section in the selected window._\")\n",
        "    else:\n",
        "        sections.append(\"\")\n",
        "        sections.append(df.head(max_rows).to_markdown(index=False))\n",
        "    sections.append(\"\")\n",
        "\n",
        "\n",
        "# Login events\n",
        "login_df = globals().get(\"login_df\")\n",
        "add_df_section(\"Login events\", login_df)\n",
        "\n",
        "# Audit EXECVE command frequency (top/bottom 5)\n",
        "sections.append(\"## Audit EXECVE command frequency\")\n",
        "exec_top5 = globals().get(\"top5\")\n",
        "exec_bottom5 = globals().get(\"bottom5\")\n",
        "if exec_top5 is None or getattr(exec_top5, \"empty\", True):\n",
        "    sections.append(\"_No EXECVE command data available in this window (or audit.log missing)._\")\n",
        "else:\n",
        "    sections.append(\"### Top 5 commands by frequency\")\n",
        "    sections.append(exec_top5.to_markdown(index=False))\n",
        "    sections.append(\"\")\n",
        "    if exec_bottom5 is not None and not exec_bottom5.empty:\n",
        "        sections.append(\"### Bottom 5 commands by frequency\")\n",
        "        sections.append(exec_bottom5.to_markdown(index=False))\n",
        "sections.append(\"\")\n",
        "\n",
        "# Executable files touched/created\n",
        "exec_fs_df = globals().get(\"exec_fs_df\")\n",
        "add_df_section(\"Executable files touched/created in window\", exec_fs_df)\n",
        "\n",
        "# SUID/SGID/sticky entries\n",
        "special_df = globals().get(\"special_df\")\n",
        "add_df_section(\"SUID/SGID/sticky bit objects\", special_df)\n",
        "\n",
        "report_md = \"\\n\".join(sections)\n",
        "report_path.write_text(report_md, encoding=\"utf-8\")\n",
        "\n",
        "print(f\"Markdown report written to: {report_path.resolve()}\")\n",
        "display(Markdown(report_md))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
